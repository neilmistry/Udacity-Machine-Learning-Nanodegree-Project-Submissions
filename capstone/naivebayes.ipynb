{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the first solution to the Toxic Comments challenge as part of my Machine Learning Capstone project.  \n",
    "\n",
    "\n",
    "Steps that we will go through are as follows:\n",
    "\n",
    "1. Import and explore the data\n",
    "2. Process the data into a format that we can train a model with\n",
    "3. Train a model\n",
    "4. Use our model to make predictions using our test sets (we have multiple, one is 20% of our training data, the other is the testing set provided by the Kaggle Competition\n",
    "5. View our accuracy, precision, recall and f1 scores\n",
    "6. Submit our testing set to the Kaggle Competition to retrive our mean-wise AUC ROC score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
      "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
      "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
      "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
      "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n",
      "5             0        0       0       0              0  \n",
      "6             1        1       0       1              0  \n",
      "7             0        0       0       0              0  \n",
      "8             0        0       0       0              0  \n",
      "9             0        0       0       0              0  \n",
      "Training set data points:  159571\n"
     ]
    }
   ],
   "source": [
    "# 1. Data importation and exploration\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test_data = pd.read_csv('test.csv') # this is our training set, with labels (provided by kaggle in csv format)\n",
    "train_data = pd.read_csv('train.csv')  # this is our testing set without labels (provided by kaggle in csv format)\n",
    "\n",
    "print(train_data.head(n=10))\n",
    "\n",
    "print('Training set data points:  ' + format(len(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 159,571 training points provided.  Each training point has a unique id label and 6 labels that classify if it falls into any category of toxic content.  From the first 10 entries we can see that point 6 is classified as being severly toxic, obscene and insulting.  Lets take a closer look at training point 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                           0002bcb3da6cb337\n",
      "comment_text     COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "toxic                                                       1\n",
      "severe_toxic                                                1\n",
      "obscene                                                     1\n",
      "threat                                                      0\n",
      "insult                                                      1\n",
      "identity_hate                                               0\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                0001d958c54c6e35\n",
      "comment_text     You, sir, are my hero. Any chance you remember...\n",
      "toxic                                                            0\n",
      "severe_toxic                                                     0\n",
      "obscene                                                          0\n",
      "threat                                                           0\n",
      "insult                                                           0\n",
      "identity_hate                                                    0\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at the testing data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
      "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
      "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
      "5  0001ea8717f6de06  Thank you for understanding. I think very high...\n",
      "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...\n",
      "7  000247e83dcc1211                   :Dear god this site is horrible.\n",
      "8  00025358d4737918  \" \\n Only a fool can believe in such numbers. ...\n",
      "9  00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double...\n"
     ]
    }
   ],
   "source": [
    "print(test_data.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the testing data does not include training labels, therefore we will partition our training set for the purpose of verifying our model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571,)\n",
      "(159571, 6)\n",
      "0    Explanation\\nWhy the edits made under my usern...\n",
      "1    D'aww! He matches this background colour I'm s...\n",
      "2    Hey man, I'm really not trying to edit war. It...\n",
      "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
      "4    You, sir, are my hero. Any chance you remember...\n",
      "5    \"\\n\\nCongratulations from me as well, use the ...\n",
      "6         COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "7    Your vandalism to the Matt Shirvington article...\n",
      "8    Sorry if the word 'nonsense' was offensive to ...\n",
      "9    alignment on this subject and which are contra...\n",
      "Name: comment_text, dtype: object\n",
      "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "0      0             0        0       0       0              0\n",
      "1      0             0        0       0       0              0\n",
      "2      0             0        0       0       0              0\n",
      "3      0             0        0       0       0              0\n",
      "4      0             0        0       0       0              0\n",
      "5      0             0        0       0       0              0\n",
      "6      1             1        1       0       1              0\n",
      "7      0             0        0       0       0              0\n",
      "8      0             0        0       0       0              0\n",
      "9      0             0        0       0       0              0\n"
     ]
    }
   ],
   "source": [
    "# 2. Process the data into a format that we can train a model with\n",
    "\n",
    "# we will seperate our training data into features and labels\n",
    "\n",
    "features = train_data['comment_text']\n",
    "label_columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "labels = train_data[label_columns]\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "print(features.head(n=10))\n",
    "print(labels.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us see a breakdown of our classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "0    144277\n",
      "1     15294\n",
      "Name: toxic, dtype: int64\n",
      "severe_toxic\n",
      "0    157976\n",
      "1      1595\n",
      "Name: severe_toxic, dtype: int64\n",
      "obscene\n",
      "0    151122\n",
      "1      8449\n",
      "Name: obscene, dtype: int64\n",
      "threat\n",
      "0    159093\n",
      "1       478\n",
      "Name: threat, dtype: int64\n",
      "insult\n",
      "0    151694\n",
      "1      7877\n",
      "Name: insult, dtype: int64\n",
      "identity_hate\n",
      "0    158166\n",
      "1      1405\n",
      "Name: identity_hate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in label_columns:\n",
    "    print (i)\n",
    "    print (train_data[i].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this histogram, we will ignore words that occur in more than 40,000*0.8 times (32,000) times.  Words that occur too frequently will not help us classify comments into these labels, because they are more than likely trivial for determining these classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# we will split the training data into training and testing data (80% will be training)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# countvectorizer will give us word counts for how many times each word \n",
    "#(dictionary will be built from all available words in our training set) occurs in each comment\n",
    "# it will also remove punctuation and extra spacing\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english', max_df = 0.32, min_df=3) \n",
    "# stop words will remove and, or, if, etc, max_df will disregard words that occur in more than xx percent of comments, \n",
    "#min_df is the minimum times a word must occur to be considered a feature\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "\n",
    "print (len(count_vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 46062 features (unique words) that will be considered when building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "Accuracy score:  0.9472975090083033\n",
      "Precision score:  0.721042471042471\n",
      "Recall score:  0.7333115183246073\n",
      "F1 score:  0.7271252433484748\n",
      "severe_toxic\n",
      "Accuracy score:  0.9842080526398246\n",
      "Precision score:  0.34925864909390447\n",
      "Recall score:  0.660436137071651\n",
      "F1 score:  0.45689655172413796\n",
      "obscene\n",
      "Accuracy score:  0.9664421118596271\n",
      "Precision score:  0.6646216768916156\n",
      "Recall score:  0.7580174927113703\n",
      "F1 score:  0.708253881776083\n",
      "threat\n",
      "Accuracy score:  0.9949240169199436\n",
      "Precision score:  0.11403508771929824\n",
      "Recall score:  0.17567567567567569\n",
      "F1 score:  0.1382978723404255\n",
      "insult\n",
      "Accuracy score:  0.9605514648284506\n",
      "Precision score:  0.5954814416352878\n",
      "Recall score:  0.6858736059479554\n",
      "F1 score:  0.6374892024186583\n",
      "identity_hate\n",
      "Accuracy score:  0.9843333855553815\n",
      "Precision score:  0.25821596244131456\n",
      "Recall score:  0.3741496598639456\n",
      "F1 score:  0.3055555555555556\n"
     ]
    }
   ],
   "source": [
    "#3. We will train our model\n",
    "#4. Use our model to make predictions using our test sets (we have multiple, one is 20% of our training data, the other is the testing set provided by the Kaggle Competition\n",
    "#5. View our accuracy, precision, recall and f1 scores\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB # this is our classifier (Naive Bayes)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # these are our metrics\n",
    "\n",
    "predictions = pd.DataFrame(columns=[label_columns]) # we will store our predictions in this variable\n",
    "test_results = pd.DataFrame(columns=['id','toxic','severe_toxic','obscene','threat','insult','identity_hate']) # we will store our predictions for kaggle in this variable\n",
    "\n",
    "test_data_transform = count_vect.transform(test_data['comment_text']) #transform our testing data using our trained countvector for Kaggle\n",
    "X_test_transform = count_vect.transform(X_test)  #transform our testing data (20% of training data) using our trained countvector\n",
    "\n",
    "for i in label_columns:\n",
    "    clf = MultinomialNB().fit(X_train_counts, y_train[i])\n",
    "    predictions[i] = clf.predict(X_test_transform)\n",
    "    test_results[i] = clf.predict(test_data_transform)\n",
    "    print (i)\n",
    "    print('Accuracy score: ', format(accuracy_score(y_test[i], predictions[i])))\n",
    "    print('Precision score: ', format(precision_score(y_test[i], predictions[i])))\n",
    "    print('Recall score: ', format(recall_score(y_test[i], predictions[i])))\n",
    "    print('F1 score: ', format(f1_score(y_test[i], predictions[i])))\n",
    "\n",
    "test_results['id'] = test_data['id']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will export the testing \n",
    "\n",
    "test_results.to_csv('naive_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This resulted in a mean-wise ROC AUC score of 0.7808 in the Kaggle competition.  We can see that although accuracy is high, our other scores are low.  There is also corellation with number of classifications in training data of each classification type and scores.  The greater number of examples we had of each classification type meant a higher score.  We will attempt other models to improve our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
